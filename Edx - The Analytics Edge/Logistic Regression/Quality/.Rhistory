squareroot(4)
squareroot = function(x)
{
x = x^2
}
squareroot(4)
x
squareroot = function(x)
{
x = x^2
}
x = squareroot(4)
x
plot(lmodel1)
par(mfrow = c(2,2))
plot(lmodel1)
library(MASS)
library(ggplot2)
head(Boston)
fix(Boston)
#pairs(Boston, upper.panel = NULL)
rownum = seq(1, nrow(Boston),1)
set.seed(1234)
train_rows = sample(rownum, 0.7*nrow(Boston))
Train = Boston[train_rows,]
Test = Boston[-train_rows,]
nrow(Train)
nrow(Test)
nrow(Train) + nrow(Test)
plot(Boston$medv, Boston$lstat)
lmodel1 = lm(medv~lstat, data = Train)
summary(lmodel1)
names(lmodel1)
lmodel1$coefficients
Train_Residuals = lmodel1$residuals
MAPE = mean(abs(Train_Residuals/Train$medv))
MAPE
coef(lmodel1)
plot(Train$medv~Train$lstat)
abline(lmodel1, lwd =2, col = "red", lty = 2)
ggplot(data = Train, aes(x = medv, y = lstat)) +
geom_point() +
stat_smooth(method = "lmodel1")
Test$results = predict(lmodel1, Test)
head(Test)
Test$Error = Test$medv - Test$results
MAPE = mean(abs(Test$Error/Test$medv))
MAPE
# lmodel1 = lm(data = Train, medv~.)
# summary(lmodel1)
#
# lmodel1 = lm(data = Train, medv~. -age)
# summary(lmodel1)
#
# lmodel1 = lm(data = Train, medv~. -age -indus -crim)
# summary(lmodel1)
lmodel1 = lm(data = Train, medv~. -age -indus)
summary(lmodel1)
lmodel1 = lm(data = Train, medv~. +lstat*age -indus)
summary(lmodel1)
plot(lmodel1$residuals)
lmodel1$residuals
par(mfrow = c(2,2))
plot(lmodel1)
plot(lmodel1)
names(lmodel1)
hist(lmodel1$residuals)
par(mfrow = c(1,1))
hist(lmodel1$residuals)
?curve
hist(lmodel1$residuals)
abline(v = mean(lmodel1$residuals))
abline(h = mean(lmodel1$residuals))
mean(lmodel1$residuals
abline(h = ))
mean(lmodel1$residuals)
abline(v = 10)
abline(v = mean(lmodel1$residuals))
hist(lmodel1$residuals)
abline(v = mean(lmodel1$residuals), col = 'red', lwd = 2)
curve(dnorm(x, mean = mean(lmodel1$residuals), sd = sd(lmodel1$residuals), add =TRUE)
curve(dnorm(x, mean = mean(lmodel1$residuals), sd = sd(lmodel1$residuals), add =TRUE)
)
curve(dnorm(x, mean = mean(lmodel1$residuals), +
sd = sd(lmodel1$residuals), add =TRUE)
curve(dnorm(x, mean=mean(lmodel1$residuals), sd=sd(lmodel1$residuals), add =TRUE)
m = mean(lmodel1$residuals)
s = sd(lmodel1$residuals)
curve(dnorm(x, mean=m, sd=s), add =TRUE)
curve(dnorm(x, mean=m, sd=s), add =TRUE)
par(mfrow = c(1,1))
hist(lmodel1$residuals)
m = mean(lmodel1$residuals)
s = sd(lmodel1$residuals)
curve(dnorm(x, mean=m, sd=s), add =TRUE)
m
s
par(mfrow = c(1,1))
hist(lmodel1$residuals)
m = mean(studres(lmodel1$residuals))
s = sd(studres(lmodel1$residuals))
curve(dnorm(x, mean=m, sd=s), add =TRUE)
par(mfrow = c(1,1))
hist(lmodel1$residuals)
m = mean(studres(lmodel1))
s = sd(studres(lmodel1))
curve(dnorm(x, mean=m, sd=s), add =TRUE)
par(mfrow = c(1,1))
hist(studres(lmodel1)
m = mean(studres(lmodel1))
s = sd(studres(lmodel1))
curve(dnorm(x, mean=m, sd=s), add =TRUE)
stuRes = studres(lmodel1)
stuRes = studres(lmodel1)
par(mfrow = c(1,1))
hist(stuRes)
stuRes = studres(lmodel1)
par(mfrow = c(1,1))
hist(stuRes, probability = TRUE)
stuRes = studres(lmodel1)
par(mfrow = c(1,1))
hist(stuRes)
hist(stuRes, probability = TRUE)
m = mean(stuRes)
s = sd(stuRes)
curve(dnorm(x, mean=m, sd=s), add =TRUE)
par(mfrow = c(1,1))
hist(lmodel1)
par(mfrow = c(1,1))
hist(lmodel1)
hist(lmodel1)
par(mfrow = c(1,1))
hist(lmodel1$residuals)
hist(lmodel1$residuals, probability = TRUE)
par(mfrow = c(1,1))
hist(lmodel1$residuals, probability = TRUE)
m = mean(lmodel1$residuals)
sd = sd(lmodel1$residuals)
curve(dnorm(x, mean = m, sd = s), add = TRUE
curve(dnorm(x, mean=m, sd=s), add = TRUE)
par(mfrow = c(1,2))
hist(stuRes)
hist(stuRes, probability = TRUE)
m = mean(stuRes)
s = sd(stuRes)
curve(dnorm(x, mean=m, sd=s), add =TRUE)
par(mfrow = c(2,1))
hist(lmodel1$residuals, probability = TRUE)
m = mean(lmodel1$residuals)
sd = sd(lmodel1$residuals)
curve(dnorm(x, mean=m, sd=s), add = TRUE)
par(mfrow = c(2,2))
hist(stuRes)
hist(stuRes, probability = TRUE)
m = mean(stuRes)
s = sd(stuRes)
curve(dnorm(x, mean=m, sd=s), add =TRUE)
par(mfrow = c(2,2))
hist(lmodel1$residuals, probability = TRUE)
m = mean(lmodel1$residuals)
sd = sd(lmodel1$residuals)
curve(dnorm(x, mean=m, sd=s), add = TRUE)
stuRes = studres(lmodel1)
par(mfrow = c(2,2))
hist(stuRes)
hist(stuRes, probability = TRUE)
m = mean(stuRes)
s = sd(stuRes)
curve(dnorm(x, mean=m, sd=s), add =TRUE)
#par(mfrow = c(2,2))
hist(lmodel1$residuals, probability = TRUE)
m = mean(lmodel1$residuals)
sd = sd(lmodel1$residuals)
curve(dnorm(x, mean=m, sd=s), add = TRUE)
stuRes = studres(lmodel1)
par(mfrow = c(2,2))
hist(stuRes, probability = TRUE)
m = mean(stuRes)
s = sd(stuRes)
curve(dnorm(x, mean=m, sd=s), add =TRUE)
#par(mfrow = c(2,2))
hist(lmodel1$residuals, probability = TRUE)
m = mean(lmodel1$residuals)
sd = sd(lmodel1$residuals)
curve(dnorm(x, mean=m, sd=s), add = TRUE)
library(car)
install.packages(car)
library()
install.packages('https://cran.r-project.org/bin/windows/contrib/3.5/car_2.1-6.zip')
install.packages('https://cran.r-project.org/bin/windows/contrib/3.5/car_2.1-6.zip')
install.packages('https://cran.r-project.org/bin/windows/contrib/3.5/car_2.1-6.zip',repos = NULL)
?repos
library(car)
update.packages(ask = FALSE, repos = "https://cloud.r-project.org")
update.packages(ask = FALSE, repos = "https://cloud.r-project.org")
library(car)
install.packages(pkbrtest)
install.packages('https://cran.r-project.org/bin/windows/contrib/3.5/pbkrtest_0.4-7.zip',repos = NULL)
library(car)
install.packages('https://cran.r-project.org/bin/windows/contrib/3.5/lme4_1.1-14.zip',repos = NULL)
library(car)
install.packages('https://cran.r-project.org/bin/windows/contrib/3.5/minqa_1.2.4.zip',repos = NULL)
library(car)
install.packages('https://cran.r-project.org/bin/windows/contrib/3.5/nloptr_1.0.4.zip',repos = NULL)
library(car)
install.packages('https://cran.r-project.org/bin/windows/contrib/3.5/quantreg_5.34.zip',repos = NULL)
library(car)
library(car)
install.packages('https://cran.r-project.org/bin/windows/contrib/3.5/SparseM_1.77.zip',repos = NULL)
library(car)
install.packages('https://cran.r-project.org/bin/windows/contrib/3.5/MatrixModels_0.4-1.zip',repos = NULL)
library(car)
library(car)
?ncvTest
?ncvTest
ncvTest(lmodel1)
lmodel1
vif(lmodel1)
library(car)
install.packages(Rcpp)
available.packages()
available.packages()[,1]
installed.packages()
installed.packages()[,1]
install.packages(Rcpp)
install.packages("Rcpp")
library(car)
library(Rcpp)
?ncvTest
library(MASS)
library(ggplot2)
head(Boston)
fix(Boston)
#pairs(Boston, upper.panel = NULL)
rownum = seq(1, nrow(Boston),1)
set.seed(1234)
train_rows = sample(rownum, 0.7*nrow(Boston))
Train = Boston[train_rows,]
Test = Boston[-train_rows,]
nrow(Train)
nrow(Test)
nrow(Train) + nrow(Test)
plot(Boston$medv, Boston$lstat)
lmodel1 = lm(medv~lstat, data = Train)
summary(lmodel1)
names(lmodel1)
lmodel1$coefficients
Train_Residuals = lmodel1$residuals
MAPE = mean(abs(Train_Residuals/Train$medv))
MAPE
coef(lmodel1)
plot(Train$medv~Train$lstat)
abline(lmodel1, lwd =2, col = "red", lty = 2)
ggplot(data = Train, aes(x = medv, y = lstat)) +
geom_point() +
stat_smooth(method = "lmodel1")
Test$results = predict(lmodel1, Test)
head(Test)
Test$Error = Test$medv - Test$results
MAPE = mean(abs(Test$Error/Test$medv))
MAPE
# lmodel1 = lm(data = Train, medv~.)
# summary(lmodel1)
#
# lmodel1 = lm(data = Train, medv~. -age)
# summary(lmodel1)
#
# lmodel1 = lm(data = Train, medv~. -age -indus -crim)
# summary(lmodel1)
lmodel1 = lm(data = Train, medv~. -age -indus)
summary(lmodel1)
lmodel1 = lm(data = Train, medv~. +lstat*age -indus)
summary(lmodel1)
plot(lmodel1$residuals)
lmodel1$residuals
par(mfrow = c(2,2))
plot(lmodel1)
names(lmodel1)
par(mfrow = c(2,2))
hist(lmodel1$residuals, probability = TRUE)
m = mean(lmodel1$residuals)
sd = sd(lmodel1$residuals)
curve(dnorm(x, mean=m, sd=s), add = TRUE)
stuRes = studres(lmodel1)
hist(stuRes, probability = TRUE)
m = mean(stuRes)
s = sd(stuRes)
curve(dnorm(x, mean=m, sd=s), add =TRUE)
# update.packages(ask = FALSE, repos = "https://cloud.r-project.org")
#
# install.packages('https://cran.r-project.org/bin/windows/contrib/3.5/car_2.1-6.zip',repos = NULL)
# install.packages('https://cran.r-project.org/bin/windows/contrib/3.5/pbkrtest_0.4-7.zip',repos = NULL)
# install.packages('https://cran.r-project.org/bin/windows/contrib/3.5/lme4_1.1-14.zip',repos = NULL)
# install.packages('https://cran.r-project.org/bin/windows/contrib/3.5/minqa_1.2.4.zip',repos = NULL)
# install.packages('https://cran.r-project.org/bin/windows/contrib/3.5/nloptr_1.0.4.zip',repos = NULL)
# install.packages('https://cran.r-project.org/bin/windows/contrib/3.5/quantreg_5.34.zip',repos = NULL)
# install.packages('https://cran.r-project.org/bin/windows/contrib/3.5/SparseM_1.77.zip',repos = NULL)
# install.packages('https://cran.r-project.org/bin/windows/contrib/3.5/MatrixModels_0.4-1.zip',repos = NULL)
#
# available.packages()[,1]
library(car)
ncvTest(lmodel1)
library(MASS)
library(ggplot2)
head(Boston)
fix(Boston)
#pairs(Boston, upper.panel = NULL)
rownum = seq(1, nrow(Boston),1)
set.seed(1234)
train_rows = sample(rownum, 0.7*nrow(Boston))
Train = Boston[train_rows,]
Test = Boston[-train_rows,]
nrow(Train)
nrow(Test)
nrow(Train) + nrow(Test)
plot(Boston$medv, Boston$lstat)
lmodel1 = lm(medv~lstat, data = Train)
summary(lmodel1)
rm(list = ls())
rm(list = ls())
setwd("F:/Ram/Data Science/GitHub/Learning-DataScience/R/Edx - The Analytics Edge/Logistic Regression")
rm(list = ls())
setwd("F:/Ram/Data Science/GitHub/Learning-DataScience/R/Edx - The Analytics Edge/Logistic Regression/Quality")
source('F:/Ram/Data Science/GitHub/Learning-DataScience/R/Edx - The Analytics Edge/Logistic Regression/Quality/Quality.R', echo=TRUE)
data_source = read.csv("quality.csv")
View(data_source)
install.packages("catools")
library("catools")
install.packages(catools)
rm(list = ls())
setwd("F:/Ram/Data Science/GitHub/Learning-DataScience/R/Edx - The Analytics Edge/Logistic Regression/Quality")
data_source = read.csv("quality.csv")
View(data_source)
install.packages(catools)
library("catools")
install.packages("catools")
install.packages("caTools")
library("caTools")
set.seed(1)
sample.split(data_source$PoorCare, SplitRatio = 3/4)
split = sample.split(data_source$PoorCare, SplitRatio = 3/4)
data_train = subset(data_source,split == TRUE)
data_test = subset(data_source,split == FALSE)
attach(data_train)
model_log1 = glm(PoorCare ~ Narcotics + OfficeVisits, data = data_train, family = binomial)
summary(model_log1)
model_log1
model_log1
predict(model_log1,type = response)
prediction_train = predict(model_log1,type = "response")
prediction_train
prediction_train2 = predict(model_log1)
prediction_train2
prediction_train
rm(list = ls())
setwd("F:/Ram/Data Science/GitHub/Learning-DataScience/R/Edx - The Analytics Edge/Flu Dynamics")
flutrain = read.csv("FluTrain.csv")
head(flutrain)
View(flutrain)
attach(flutrain)
Week[which.max(ILI)]
Week[which.max(Queries)]
hist(ILI)
boxplot(ILI)
lILI = log(ILI)
plot(lILI ~ Queries)
lmodel1 = lm(log(ILI)~ Queries, data = flutrain)
lmodel1
lmodel1$fitted.values
rm(list = ls())
setwd("F:/Ram/Data Science/GitHub/Learning-DataScience/R/Edx - The Analytics Edge/Logistic Regression/Quality")
data_source = read.csv("quality.csv")
View(data_source)
install.packages("caTools")
library("caTools")
set.seed(1)
split = sample.split(data_source$PoorCare, SplitRatio = 3/4)
data_train = subset(data_source,split == TRUE)
data_test = subset(data_source,split == FALSE)
attach(data_train)
model_log1 = glm(PoorCare ~ Narcotics + OfficeVisits, data = data_train, family = binomial)
summary(model_log1)
prediction_train = predict(model_log1,type = "response")
prediction_train2 = predict(model_log1)
install.packages("caTools")
rm(list = ls())
setwd("F:/Ram/Data Science/GitHub/Learning-DataScience/R/Edx - The Analytics Edge/Logistic Regression/Quality")
data_source = read.csv("quality.csv")
View(data_source)
# install.packages("caTools")
library("caTools")
set.seed(1)
split = sample.split(data_source$PoorCare, SplitRatio = 3/4)
data_train = subset(data_source,split == TRUE)
data_test = subset(data_source,split == FALSE)
attach(data_train)
model_log1 = glm(PoorCare ~ Narcotics + OfficeVisits, data = data_train, family = binomial)
summary(model_log1)
prediction_train = predict(model_log1,type = "response")
prediction_train2 = predict(model_log1)
rm(list = ls())
setwd("F:/Ram/Data Science/GitHub/Learning-DataScience/R/Edx - The Analytics Edge/Logistic Regression/Quality")
data_source = read.csv("quality.csv")
View(data_source)
# install.packages("caTools")
library("caTools")
set.seed(1)
split = sample.split(data_source$PoorCare, SplitRatio = 3/4)
data_train = subset(data_source,split == TRUE)
data_test = subset(data_source,split == FALSE)
attach(data_train)
model_log1 = glm(PoorCare ~ Narcotics + OfficeVisits, data = data_train, family = binomial)
summary(model_log1)
prediction_train = predict(model_log1,type = "response")
prediction_train
# Unit 3, Modeling the Expert
# Video 4
# Read in dataset
quality = read.csv("quality.csv")
# Look at structure
str(quality)
# Table outcome
table(quality$PoorCare)
# Baseline accuracy
98/131
# Install and load caTools package
install.packages("caTools")
library(caTools)
# Randomly split data
set.seed(88)
split = sample.split(quality$PoorCare, SplitRatio = 0.75)
split
# Create training and testing sets
qualityTrain = subset(quality, split == TRUE)
qualityTest = subset(quality, split == FALSE)
# Logistic Regression Model
QualityLog = glm(PoorCare ~ OfficeVisits + Narcotics, data=qualityTrain, family=binomial)
summary(QualityLog)
# Make predictions on training set
predictTrain = predict(QualityLog, type="response")
install.packages("caTools")
# Unit 3, Modeling the Expert
# Video 4
# Read in dataset
quality = read.csv("quality.csv")
# Look at structure
str(quality)
# Table outcome
table(quality$PoorCare)
# Baseline accuracy
98/131
# Install and load caTools package
# install.packages("caTools")
library(caTools)
# Randomly split data
set.seed(88)
split = sample.split(quality$PoorCare, SplitRatio = 0.75)
split
# Create training and testing sets
qualityTrain = subset(quality, split == TRUE)
qualityTest = subset(quality, split == FALSE)
# Logistic Regression Model
QualityLog = glm(PoorCare ~ OfficeVisits + Narcotics, data=qualityTrain, family=binomial)
summary(QualityLog)
# Make predictions on training set
predictTrain = predict(QualityLog, type="response")
predictTrain
# Analyze predictions
summary(predictTrain)
tapply(predictTrain, qualityTrain$PoorCare, mean)
rm(list = ls())
setwd("F:/Ram/Data Science/GitHub/Learning-DataScience/R/Edx - The Analytics Edge/Logistic Regression/Quality")
data_source = read.csv("quality.csv")
View(data_source)
# install.packages("caTools")
library("caTools")
set.seed(1)
split = sample.split(data_source$PoorCare, SplitRatio = 3/4)
data_train = subset(data_source,split == TRUE)
data_test = subset(data_source,split == FALSE)
attach(data_train)
model_log1 = glm(PoorCare ~ Narcotics + OfficeVisits, data = data_train, family = binomial)
summary(model_log1)
prediction_train = predict(model_log1,type = "response")
table(prediction_train,data_train$PoorCare, mean)
nrow(prediction_train)
prediction_train
tapply(prediction_train,data_train$PoorCare,mean)
rm(list = ls())
setwd("F:/Ram/Data Science/GitHub/Learning-DataScience/R/Edx - The Analytics Edge/Logistic Regression/Quality")
data_source = read.csv("quality.csv")
View(data_source)
# install.packages("caTools")
library("caTools")
set.seed(88)
split = sample.split(data_source$PoorCare, SplitRatio = 3/4)
data_train = subset(data_source,split == TRUE)
data_test = subset(data_source,split == FALSE)
attach(data_train)
model_log2 = glm(PoorCare ~ StartedOnCombination + ProviderCount, data = data_train, family = binomial())
detach(data_train)
summary(model_log2)
prediction_train2 = predict(model_log2, type = response)
prediction_train2 = predict(model_log2, type = "response")
prediction_train2
tapply(StartedOnCombination, PoorCare, mean)
tapply(PoorCare, StartedOnCombination, mean)
tapply(StartedOnCombination, prediction_train2, mean)
tapply(prediction_train2,StartedOnCombination, mean)
table(data_train$PoorCare,prediction_train2 > 0.5)
summary(model_log2)
summary(model_log1)
